# プロジェクト取り組み報告書

本プロジェクトでは、高解像度の製品画像から微細な不良（Defect）を検出するための深層学習モデルの開発と、その評価・可視化パイプラインの構築を行いました。
以下に、主要な技術的取り組みと実装の詳細をまとめます。

## 1. コア戦略：パッチベース学習
1024x1024ピクセルという高解像度の元画像を、そのままCNNに入力するのは計算リソースと特徴抽出の観点から非効率でした。
そこで、**224x224ピクセルのパッチ（小領域）** を単位として学習・推論を行う戦略を採用しました。

*   **学習時 (Training)**:
    *   `src/dataset.py` にて `RandomCrop(224)` を適用し、元画像からランダムに欠陥部分や正常部分を切り出して学習させました。
    *   これにより、データのバリエーションを増やし（Data Augmentation効果）、モデルの汎化性能を高めました。
*   **推論・評価時 (Inference/Evaluation)**:
    *   `src/evaluator.py` にて **スライディングウィンドウ方式** を実装しました。
    *   元画像全体をオーバーラップさせながら網羅的に切り出し、全てのパッチを推論します。

## 2. モデル構築：転移学習の最適化
限られたデータ量で高い精度を達成するため、**転移学習 (Transfer Learning)** を活用しました。

*   **アーキテクチャ**: `ResNet18` (ImageNet事前学習済み)
*   **工夫点**:
    *   初期の実験ではカスタム層を追加していましたが、学習の安定性を最優先し、標準的なResNet構造（`avgpool` -> `fc`）に戻しました。
    *   これにより、ImageNetで学習された強力な特徴抽出能力を最大限に活かし、収束を早めることに成功しました。

## 3. 不均衡データ対策
良品（Good）に対して不良品（Bad）のサンプル数が少ないという課題に対し、以下の対策を講じました。

*   **重み付き損失関数 (Weighted Loss)**:
    *   `src/config.py` および `main.py` にて、クラス間のサンプル比率（約1:2.86）に基づき、Badクラスの誤答ペナルティを重く設定しました。
    *   これにより、モデルが「全て良品と予測すれば正解率が高い」という局所解に陥るのを防ぎ、**再現率 (Recall)** の向上を実現しました。

## 4. 評価ロジック：ORゲート判定
パッチ単位の推論結果を、画像単位の判定（良品/不良品）に統合するためのロジックを構築しました。

*   **Max-Pooling (ORゲート) 戦略**:
    *   画像から切り出された数十枚のパッチのうち、**1枚でも**不良の確率が高いものがあれば、その画像全体を「不良品」と判定します。
    *   **閾値調整**: 誤検知（False Positive）を制御するため、判定閾値（`THRESHOLD`）を `0.8` に設定し、自信がある場合のみ不良と判定するように調整しました。

## 5. 説明可能性 (XAI)：Grad-CAMの実装
モデルが「画像のどこを見て不良と判断したか」を可視化するため、**Grad-CAM** を実装しました。

*   **独自実装**:
    *   外部ライブラリに依存せず、`src/visualization.py` に独自の `GradCAM` クラスを実装しました。
    *   最終畳み込み層の勾配を用いてヒートマップを生成し、元画像に重ね合わせて表示します。
*   **運用**:
    *   評価時に、正しく検知できた不良品（True Positive）だけでなく、誤って不良と判定された良品（False Positive）のヒートマップも自動生成します。
    *   これにより、「光の反射を傷と誤認している」といったモデルの弱点を分析可能にしました。

## 6. コード品質：リファクタリング
提出品質のコードにするため、モジュール構成を整理しました。

*   **設定の集約**: `src/config.py` にハイパーパラメータを一元化。
*   **関数の共通化**: `src/utils.py` に乱数固定やデバイス選択などの処理を分離。
*   **依存関係の整理**: 各モジュール（`models.py`, `dataset.py` 等）の役割を明確化。
